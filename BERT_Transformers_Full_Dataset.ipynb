{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPygYH6SLqJp"
   },
   "outputs": [],
   "source": [
    "!pip install -q ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yS5-9OpkzV1d",
    "outputId": "5298c2d7-0235-4ee2-958c-e4ff48d4a7f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNDdwSwdzSZT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "import transformers\n",
    "import unicodedata\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLZLXpPSAYRK"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Input_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bp1_vgsHAYUL",
    "outputId": "759e6b34-4f48-45e6-e047-c2502e201461"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0KZOvAiAYW3"
   },
   "outputs": [],
   "source": [
    "def clean_misspell(text):\n",
    "    misspell_to_sub = {\n",
    "        '(T|t)erroristan': 'terrorist Pakistan',\n",
    "        'BIMARU': 'Bihar, Madhya Pradesh, Rajasthan, Uttar Pradesh',\n",
    "        '(H|h)induphobic': 'Hindu phobic',\n",
    "        '(H|h)induphobia': 'Hindu phobic',\n",
    "        'Babchenko': 'Arkady Arkadyevich Babchenko faked death',\n",
    "        'Boshniaks': 'Bosniaks',\n",
    "        'Dravidanadu': 'Dravida Nadu',\n",
    "        'mysoginists': 'misogynists',\n",
    "        'MGTOWS': 'Men Going Their Own Way',\n",
    "        'mongloid': 'Mongoloid',\n",
    "        'unsincere': 'insincere',\n",
    "        'meninism': 'male feminism',\n",
    "        'jewplicate': 'jewish replicate',\n",
    "        'unoin': 'Union',\n",
    "        'daesh': 'Islamic State of Iraq and the Levant',\n",
    "        'Kalergi': 'Coudenhove-Kalergi',\n",
    "        ' apist': ' Ape',\n",
    "        '(B|b)hakts': 'Bhakt',\n",
    "        'Tambrahms': 'Tamil Brahmin',\n",
    "        'Pahul': 'Amrit Sanskar',\n",
    "        'SJW(s|)': 'social justice warrior',\n",
    "        'incel(s|)': 'involuntary celibates',\n",
    "        'emiratis': 'Emiratis',\n",
    "        'weatern': 'western',\n",
    "        'Pizzagate': 'Pizzagate conspiracy theory',\n",
    "        'naïve': 'naive',\n",
    "        'Skripal': 'Sergei Skripal',\n",
    "        '(R|r)emainers': 'remainer',\n",
    "        'antibrahmin': 'anti Brahminism',\n",
    "        'HYPSM': ' Harvard, Yale, Princeton, Stanford, MIT',\n",
    "        'HYPS': ' Harvard, Yale, Princeton, Stanford',\n",
    "        'kompromat': 'compromising material',\n",
    "        '(T|t)harki': 'pervert',\n",
    "        'mastuburate': 'masturbate',\n",
    "        'Zoë': 'Zoe',\n",
    "        'indans': 'Indian',\n",
    "        'xender': 'gender',\n",
    "        'Naxali': 'Naxalite',\n",
    "        'Bathla': 'Namit Bathla',\n",
    "        'Mewani': 'Indian politician Jignesh Mevani',\n",
    "        'clichéd': 'cliché',\n",
    "        'cliché(s|)': 'cliché',\n",
    "        'Wjy': 'Why',\n",
    "        'Fadnavis': 'Indian politician Devendra Fadnavis',\n",
    "        'Awadesh': 'Indian engineer Awdhesh Singh',\n",
    "        'Awdhesh': 'Indian engineer Awdhesh Singh',\n",
    "        'Khalistanis': 'Sikh separatist movement',\n",
    "        'madheshi': 'Madheshi',\n",
    "        'Quorans': 'Quoran',\n",
    "        'BNBR': 'Be Nice, Be Respectful',\n",
    "        'Bolsonaro': 'Jair Bolsonaro',\n",
    "        'XXXTentacion': 'Tentacion',\n",
    "        'Padmavat': 'Indian Movie Padmaavat',\n",
    "        'Žižek': 'Slovenian philosopher Slavoj Žižek',\n",
    "        'Adityanath': 'Indian monk Yogi Adityanath',\n",
    "        '(B|b)rexit': 'British Exit',\n",
    "        'jallikattu': 'Jallikattu',\n",
    "        'fortnite': 'Fortnite',\n",
    "        'Swachh': 'Swachh Bharat mission campaign',\n",
    "        'Qoura': 'Quora',\n",
    "        'narcissit': 'narcissist',\n",
    "        # extra in sample\n",
    "        'Doklam': 'Tibet',\n",
    "        'Drumpf': 'Donald Trump',\n",
    "        'Strzok': 'Hillary Clinton scandal',\n",
    "        'rohingya': 'Rohingya',\n",
    "        'wumao': 'offensive Chinese',\n",
    "        'Sanghis': 'Sanghi',\n",
    "        'Tamilans': 'Tamils',\n",
    "        'biharis': 'Biharis',\n",
    "        'Rejuvalex': 'hair growth formula',\n",
    "        'Feku': 'The Man of India',\n",
    "        'deplorables': 'deplorable',\n",
    "        'muhajirs': 'Muslim immigrants',\n",
    "        'Brexiters': 'British Exit supporters',\n",
    "        'Brexiteers': 'British Exit supporters',\n",
    "        'Brexiting': 'British Exit',\n",
    "        'Gujratis': 'Gujarati',\n",
    "        'Chutiya': 'Tibet people',\n",
    "        'thighing': 'masturbate',\n",
    "        '卐': 'Nazi Germany',\n",
    "        'rohingyas': 'Muslim ethnic group',\n",
    "        'Pribumi': 'Native Indonesians',\n",
    "        'Gurmehar': 'Gurmehar Kaur Indian student activist',\n",
    "        'Novichok': 'Soviet Union agents',\n",
    "        'Khazari': 'Khazars',\n",
    "        'Demonetization': 'demonetization',\n",
    "        'demonetisation': 'demonetization',\n",
    "        'cryptocurrencies': 'bitcoin',\n",
    "        'Hindians': 'offensive Indian',\n",
    "        'vaxxers': 'vocal nationalists',\n",
    "        'remoaners': 'remainer',\n",
    "        'Jewism': 'Judaism',\n",
    "        'Eroupian': 'European',\n",
    "        'WMAF': 'White male Asian female',\n",
    "        'moeslim': 'Muslim',\n",
    "        'cishet': 'cisgender and heterosexual person',\n",
    "        'Eurocentrics': 'Eurocentrism',\n",
    "        'Jewdar': 'Jew dar',\n",
    "        'Asifas': 'abduction, rape, murder case',\n",
    "        'marathis': 'Marathi',\n",
    "        'Trumpanzees': 'Trump chimpanzee',\n",
    "        'quoras': 'Quora',\n",
    "        'Crimeans': 'Crimea people',\n",
    "        'atrracted': 'attract',\n",
    "        'LGBT': 'lesbian, gay, bisexual, transgender',\n",
    "        'Boshniaks': 'Bosniaks',\n",
    "        'Myeshia': 'widow of Green Beret killed in Niger',\n",
    "        'demcoratic': 'Democratic',\n",
    "        'raaping': 'rape',\n",
    "        'Dönmeh': 'Islam',\n",
    "        'feminazism': 'feminism nazi',\n",
    "        'Quroa': 'Quora',\n",
    "        'QUORA': 'Quora',\n",
    "        'langague': 'language',\n",
    "        '(H|h)ongkongese': 'HongKong people',\n",
    "        '(K|k)ashmirians': 'Kashmirian',\n",
    "        '(C|c)hodu': 'fucker',\n",
    "        'penish': 'penis',\n",
    "        'micropenis': 'small penis',\n",
    "        'Madridiots': 'Madrid idiot',\n",
    "        'Ambedkarites': 'Dalit Buddhist movement',\n",
    "        'ReleaseTheMemo': 'cry for the right and Trump supporters',\n",
    "        'harrase': 'harass',\n",
    "        '(B|b)arracoon': 'Black slave',\n",
    "        '(C|c)astrater': 'castration',\n",
    "        '(R|r)apistan': 'rapist Pakistan',\n",
    "        '(T|t)urkified': 'Turkification',\n",
    "        'Dumbassistan': 'dumb ass Pakistan',\n",
    "        'facetards': 'Facebook retards',\n",
    "        'rapefugees': 'rapist refugee',\n",
    "        'superficious': 'superficial',\n",
    "        # extra from kagglers\n",
    "        'colour': 'color',\n",
    "        'centre': 'center',\n",
    "        'favourite': 'favorite',\n",
    "        'travelling': 'traveling',\n",
    "        'counselling': 'counseling',\n",
    "        'theatre': 'theater',\n",
    "        'cancelled': 'canceled',\n",
    "        'labour': 'labor',\n",
    "        'organisation': 'organization',\n",
    "        'wwii': 'world war 2',\n",
    "        'citicise': 'criticize',\n",
    "        'youtu ': 'youtube ',\n",
    "        'Qoura': 'Quora',\n",
    "        'sallary': 'salary',\n",
    "        'Whta': 'What',\n",
    "        'narcisist': 'narcissist',\n",
    "        'narcissit': 'narcissist',\n",
    "        'howdo': 'how do',\n",
    "        'whatare': 'what are',\n",
    "        'howcan': 'how can',\n",
    "        'howmuch': 'how much',\n",
    "        'howmany': 'how many',\n",
    "        'whydo': 'why do',\n",
    "        'doI': 'do I',\n",
    "        'theBest': 'the best',\n",
    "        'howdoes': 'how does',\n",
    "        'mastrubation': 'masturbation',\n",
    "        'mastrubate': 'masturbate',\n",
    "        'mastrubating': 'masturbating',\n",
    "        'pennis': 'penis',\n",
    "        'Etherium': 'Ethereum',\n",
    "        'bigdata': 'big data',\n",
    "        '2k17': '2017',\n",
    "        '2k18': '2018',\n",
    "        'qouta': 'quota',\n",
    "        'exboyfriend': 'ex boyfriend',\n",
    "        'airhostess': 'air hostess',\n",
    "        'whst': 'what',\n",
    "        'watsapp': 'whatsapp',\n",
    "        'demonitisation': 'demonetization',\n",
    "        'demonitization': 'demonetization',\n",
    "        'demonetisation': 'demonetization'\n",
    "    }\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_to_sub.keys()))\n",
    "\n",
    "    def _replace(match):\n",
    "        return misspell_to_sub.get(match.group(0), match.group(0))\n",
    "    return misspell_re.sub(_replace, text)\n",
    "def spacing_misspell(text):\n",
    "    \"\"\"\n",
    "    'deadbody' -> 'dead body'\n",
    "    \"\"\"\n",
    "    misspell_list = [\n",
    "        'body',\n",
    "        '(D|d)ead',\n",
    "        '(N|n)orth',\n",
    "        '(K|k)orea',\n",
    "        'matrix',\n",
    "        '(S|s)hit',\n",
    "        '(F|f)uck',\n",
    "        '(F|f)uk',\n",
    "        '(F|f)ck',\n",
    "        '(D|d)ick',\n",
    "        'Trump',\n",
    "        '\\W(A|a)nti',\n",
    "        '(W|w)hy',\n",
    "        # 'Jew',\n",
    "        'bait',\n",
    "        'care',\n",
    "        'troll',\n",
    "        'over',\n",
    "        'gender',\n",
    "        'people',\n",
    "        'kind',\n",
    "        '(S|s)ick',\n",
    "        '(S|s)uck',\n",
    "        '(I|i)diot',\n",
    "        # 'hole(s|)\\W',\n",
    "        '(B|b)ooty',\n",
    "        '(C|c)oin(s|)\\W',\n",
    "        '\\W(N|n)igger'\n",
    "    ]\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_list))\n",
    "    return misspell_re.sub(r\" \\1 \", text)\n",
    "\n",
    "\n",
    "def clean_latex(text):\n",
    "    \"\"\"\n",
    "    convert r\"[math]\\vec{x} + \\vec{y}\" to English\n",
    "    \"\"\"\n",
    "    # edge case\n",
    "    text = re.sub(r'\\[math\\]', ' LaTex math ', text)\n",
    "    text = re.sub(r'\\[\\/math\\]', ' LaTex math ', text)\n",
    "    text = re.sub(r'\\\\', ' LaTex ', text)\n",
    "\n",
    "    pattern_to_sub = {\n",
    "        r'\\\\mathrm': ' LaTex math mode ',\n",
    "        r'\\\\mathbb': ' LaTex math mode ',\n",
    "        r'\\\\boxed': ' LaTex equation ',\n",
    "        r'\\\\begin': ' LaTex equation ',\n",
    "        r'\\\\end': ' LaTex equation ',\n",
    "        r'\\\\left': ' LaTex equation ',\n",
    "        r'\\\\right': ' LaTex equation ',\n",
    "        r'\\\\(over|under)brace': ' LaTex equation ',\n",
    "        r'\\\\text': ' LaTex equation ',\n",
    "        r'\\\\vec': ' vector ',\n",
    "        r'\\\\var': ' variable ',\n",
    "        r'\\\\theta': ' theta ',\n",
    "        r'\\\\mu': ' average ',\n",
    "        r'\\\\min': ' minimum ',\n",
    "        r'\\\\max': ' maximum ',\n",
    "        r'\\\\sum': ' + ',\n",
    "        r'\\\\times': ' * ',\n",
    "        r'\\\\cdot': ' * ',\n",
    "        r'\\\\hat': ' ^ ',\n",
    "        r'\\\\frac': ' / ',\n",
    "        r'\\\\div': ' / ',\n",
    "        r'\\\\sin': ' Sine ',\n",
    "        r'\\\\cos': ' Cosine ',\n",
    "        r'\\\\tan': ' Tangent ',\n",
    "        r'\\\\infty': ' infinity ',\n",
    "        r'\\\\int': ' integer ',\n",
    "        r'\\\\in': ' in ',\n",
    "    }\n",
    "    # post process for look up\n",
    "    pattern_dict = {k.strip('\\\\'): v for k, v in pattern_to_sub.items()}\n",
    "    # init re\n",
    "    patterns = pattern_to_sub.keys()\n",
    "    pattern_re = re.compile('(%s)' % '|'.join(patterns))\n",
    "\n",
    "    def _replace(match):\n",
    "        return pattern_dict.get(match.group(0).strip('\\\\'), match.group(0))\n",
    "    return pattern_re.sub(_replace, text)\n",
    "def normalize_unicode(text):\n",
    "    \"\"\"\n",
    "    unicode string normalization\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize('NFKD', text)\n",
    "\n",
    "\n",
    "def remove_newline(text):\n",
    "    \"\"\"\n",
    "    remove \\n and  \\t\n",
    "    \"\"\"\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\t', ' ', text)\n",
    "    text = re.sub('\\b', ' ', text)\n",
    "    text = re.sub('\\r', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def decontracted(text):\n",
    "    \"\"\"\n",
    "    de-contract the contraction\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    text = re.sub(r\"(W|w)on(\\'|\\’)t\", \"will not\", text)\n",
    "    text = re.sub(r\"(C|c)an(\\'|\\’)t\", \"can not\", text)\n",
    "    text = re.sub(r\"(Y|y)(\\'|\\’)all\", \"you all\", text)\n",
    "    text = re.sub(r\"(Y|y)a(\\'|\\’)ll\", \"you all\", text)\n",
    "\n",
    "    # general\n",
    "    text = re.sub(r\"(I|i)(\\'|\\’)m\", \"i am\", text)\n",
    "    text = re.sub(r\"(A|a)in(\\'|\\’)t\", \"is not\", text)\n",
    "    text = re.sub(r\"n(\\'|\\’)t\", \" not\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)re\", \" are\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)s\", \" is\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)d\", \" would\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ll\", \" will\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)t\", \" not\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ve\", \" have\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def spacing_punctuation(text):\n",
    "    \"\"\"\n",
    "    add space before and after punctuation and symbols\n",
    "    \"\"\"\n",
    "    regular_punct = list(string.punctuation)\n",
    "    extra_punct = [\n",
    "        ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "        '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    "        '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
    "        '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
    "        '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
    "        '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
    "        '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "        'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
    "        '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
    "        '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
    "    all_punct = ''.join(sorted(list(set(regular_punct + extra_punct))))\n",
    "    re_tok = re.compile(f'([{all_punct}])')\n",
    "    return re_tok.sub(r' \\1 ', text)\n",
    "\n",
    "\n",
    "def spacing_digit(text):\n",
    "    \"\"\"\n",
    "    add space before and after digits\n",
    "    \"\"\"\n",
    "    re_tok = re.compile('([0-9])')\n",
    "    return re_tok.sub(r' \\1 ', text)\n",
    "\n",
    "\n",
    "def spacing_number(text):\n",
    "    \"\"\"\n",
    "    add space before and after numbers\n",
    "    \"\"\"\n",
    "    re_tok = re.compile('([0-9]{1,})')\n",
    "    return re_tok.sub(r' \\1 ', text)\n",
    "\n",
    "\n",
    "def remove_number(text):\n",
    "    \"\"\"\n",
    "    numbers are not toxic\n",
    "    \"\"\"\n",
    "    return re.sub('\\d+', ' ', text)\n",
    "\n",
    "\n",
    "def remove_space(text):\n",
    "    \"\"\"\n",
    "    remove extra spaces and ending space if any\n",
    "    \"\"\"\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub('\\s+$', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess(text, remove_num=True):\n",
    "    \"\"\"\n",
    "    preprocess text into clean text for tokenization\n",
    "    \"\"\"\n",
    "    # 1. normalize\n",
    "    text = normalize_unicode(text)\n",
    "    # # 2. remove new line\n",
    "    text = remove_newline(text)\n",
    "    # 3. de-contract\n",
    "    text = decontracted(text)\n",
    "    # 4. clean misspell\n",
    "    text = clean_misspell(text)\n",
    "    # 5. space misspell\n",
    "    text = spacing_misspell(text)\n",
    "    # 6. clean_latex\n",
    "    text = clean_latex(text)\n",
    "    # 7. space\n",
    "    text = spacing_punctuation(text)\n",
    "    # 8. handle number\n",
    "    if remove_num:\n",
    "        text = remove_number(text)\n",
    "    else:\n",
    "        text = spacing_digit(text)\n",
    "    # 9. remove space\n",
    "    text = remove_space(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agkIudTaAYZf"
   },
   "outputs": [],
   "source": [
    "df['question_text'] = df['question_text'].apply(lambda s: preprocess(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPPCkNYCAYcL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcYxin-20Ntz",
    "outputId": "946dd140-c6ef-458b-802c-be349b361b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044897, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhUqScS-0Puh",
    "outputId": "d78676e5-bd1a-4654-b4d5-d9ee5d081260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261225, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVL9xvtKqcRA"
   },
   "outputs": [],
   "source": [
    "X_train = df_train['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hrKvb_Rc7NMf",
    "outputId": "bb7dd2a7-2d0b-4762-bd1b-207ea5369c2a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'How is strategic positioning is different from marketing positioning ?'"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = list(X_train)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xGDjB9Q65KyO",
    "outputId": "d2748f1e-5d98-480f-cec5-d302df99b7e3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'What is the most effective classroom management skill / technique to create a good learning environment ?'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_test['question_text']\n",
    "X_test = list(X_test)\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyMYOtJw0a7o"
   },
   "outputs": [],
   "source": [
    "y_train = df_train.target\n",
    "y_train = list(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiFJuNIp5K1Q"
   },
   "outputs": [],
   "source": [
    "y_test = df_test.target\n",
    "y_test = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwMEroWn6iMU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "Lt0SoFxq5K62",
    "outputId": "b92e309f-8b09-4d3e-f279-c2b8ae868c5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ktrain/text/preprocessor.py:388: UserWarning: The class_names argument is replacing the classes argument. Please update your code.\n",
      "  warnings.warn('The class_names argument is replacing the classes argument. Please update your code.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 15\n",
      "\t95percentile : 31\n",
      "\t99percentile : 45\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 15\n",
      "\t95percentile : 31\n",
      "\t99percentile : 45\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'bert-base-cased'\n",
    "t = text.Transformer(MODEL_NAME, maxlen=100, classes=[0,1])\n",
    "trn = t.preprocess_train(X_train, y_train)\n",
    "val = t.preprocess_test(X_test, y_test)\n",
    "model = t.get_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VGNBnLH4bQE"
   },
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLrIiadT5rpO",
    "outputId": "5b4ce16c-5ce8-4131-afb0-a3101000f416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 1e-05...\n",
      "56961/65307 [=========================>....] - ETA: 47:31 - loss: 0.1034 - accuracy: 0.9589Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "learner.fit_onecycle(0.00001, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhNpsX8GD-tk",
    "outputId": "ac7d2033-7c12-4413-e020-75cfdd93e34d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    245369\n",
      "           1       0.73      0.68      0.70     15856\n",
      "\n",
      "    accuracy                           0.97    261225\n",
      "   macro avg       0.85      0.83      0.84    261225\n",
      "weighted avg       0.96      0.97      0.96    261225\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[241369,   4000],\n",
       "       [  5109,  10747]])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCJTceq-_Klu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_Transformers_Full_Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
