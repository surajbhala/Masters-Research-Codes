{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pPygYH6SLqJp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate,GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LB72FCLELsNX",
    "outputId": "347ec668-ca1b-42af-befe-c03b93c520bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data with shape :  (1306122, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"Input_Data.csv\")\n",
    "print(\"Input data with shape : \", df.shape)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "vTxnywFypMs7",
    "outputId": "19872196-839a-448f-a734-b24c8af2f1cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RfqfOSQdMk3X"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['qid'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dwmy6dhyMxWv",
    "outputId": "2944f3e5-b212-4394-b855-3bcec3ceb8cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Wtb4xWQ8Myb8"
   },
   "outputs": [],
   "source": [
    "df_sincere = df.loc[df['target'] == 0]\n",
    "df_insincere = df.loc[df['target'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "A30yPIC4PnLw"
   },
   "outputs": [],
   "source": [
    "df_sincere_sampled = df_sincere.sample(80000,random_state=42)\n",
    "df_insincere_sampled = df_insincere.sample(80000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "eNE6rb87PnPI",
    "outputId": "51f74934-8751-4aca-ff0b-12ed0da15df6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sincere_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Idw1MWtJPnRs"
   },
   "outputs": [],
   "source": [
    "df_main = pd.concat([df_insincere_sampled,df_sincere_sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HBy8YMxuPnU6",
    "outputId": "80a0a68b-2933-470e-af2b-2daacb847c3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPX6ZiXqNOd8"
   },
   "outputs": [],
   "source": [
    "def clean_misspell(text):\n",
    "    \"\"\"\n",
    "    misspell list (quora vs. glove)\n",
    "    \"\"\"\n",
    "    misspell_to_sub = {\n",
    "        '(T|t)erroristan': 'terrorist Pakistan',\n",
    "        'BIMARU': 'Bihar, Madhya Pradesh, Rajasthan, Uttar Pradesh',\n",
    "        '(H|h)induphobic': 'Hindu phobic',\n",
    "        '(H|h)induphobia': 'Hindu phobic',\n",
    "        'Babchenko': 'Arkady Arkadyevich Babchenko faked death',\n",
    "        'Boshniaks': 'Bosniaks',\n",
    "        'Dravidanadu': 'Dravida Nadu',\n",
    "        'mysoginists': 'misogynists',\n",
    "        'MGTOWS': 'Men Going Their Own Way',\n",
    "        'mongloid': 'Mongoloid',\n",
    "        'unsincere': 'insincere',\n",
    "        'meninism': 'male feminism',\n",
    "        'jewplicate': 'jewish replicate',\n",
    "        'unoin': 'Union',\n",
    "        'daesh': 'Islamic State of Iraq and the Levant',\n",
    "        'Kalergi': 'Coudenhove-Kalergi',\n",
    "        ' apist': ' Ape',\n",
    "        '(B|b)hakts': 'Bhakt',\n",
    "        'Tambrahms': 'Tamil Brahmin',\n",
    "        'Pahul': 'Amrit Sanskar',\n",
    "        'SJW(s|)': 'social justice warrior',\n",
    "        'incel(s|)': 'involuntary celibates',\n",
    "        'emiratis': 'Emiratis',\n",
    "        'weatern': 'western',\n",
    "        'Pizzagate': 'Pizzagate conspiracy theory',\n",
    "        'naïve': 'naive',\n",
    "        'Skripal': 'Sergei Skripal',\n",
    "        '(R|r)emainers': 'remainer',\n",
    "        'antibrahmin': 'anti Brahminism',\n",
    "        'HYPSM': ' Harvard, Yale, Princeton, Stanford, MIT',\n",
    "        'HYPS': ' Harvard, Yale, Princeton, Stanford',\n",
    "        'kompromat': 'compromising material',\n",
    "        '(T|t)harki': 'pervert',\n",
    "        'mastuburate': 'masturbate',\n",
    "        'Zoë': 'Zoe',\n",
    "        'indans': 'Indian',\n",
    "        'xender': 'gender',\n",
    "        'Naxali': 'Naxalite',\n",
    "        'Bathla': 'Namit Bathla',\n",
    "        'Mewani': 'Indian politician Jignesh Mevani',\n",
    "        'clichéd': 'cliché',\n",
    "        'cliché(s|)': 'cliché',\n",
    "        'Wjy': 'Why',\n",
    "        'Fadnavis': 'Indian politician Devendra Fadnavis',\n",
    "        'Awadesh': 'Indian engineer Awdhesh Singh',\n",
    "        'Awdhesh': 'Indian engineer Awdhesh Singh',\n",
    "        'Khalistanis': 'Sikh separatist movement',\n",
    "        'madheshi': 'Madheshi',\n",
    "        'Quorans': 'Quoran',\n",
    "        'BNBR': 'Be Nice, Be Respectful',\n",
    "        'Bolsonaro': 'Jair Bolsonaro',\n",
    "        'XXXTentacion': 'Tentacion',\n",
    "        'Padmavat': 'Indian Movie Padmaavat',\n",
    "        'Žižek': 'Slovenian philosopher Slavoj Žižek',\n",
    "        'Adityanath': 'Indian monk Yogi Adityanath',\n",
    "        '(B|b)rexit': 'British Exit',\n",
    "        'jallikattu': 'Jallikattu',\n",
    "        'fortnite': 'Fortnite',\n",
    "        'Swachh': 'Swachh Bharat mission campaign',\n",
    "        'Qoura': 'Quora',\n",
    "        'narcissit': 'narcissist',\n",
    "        # extra in sample\n",
    "        'Doklam': 'Tibet',\n",
    "        'Drumpf': 'Donald Trump',\n",
    "        'Strzok': 'Hillary Clinton scandal',\n",
    "        'rohingya': 'Rohingya',\n",
    "        'wumao': 'offensive Chinese',\n",
    "        'Sanghis': 'Sanghi',\n",
    "        'Tamilans': 'Tamils',\n",
    "        'biharis': 'Biharis',\n",
    "        'Rejuvalex': 'hair growth formula',\n",
    "        'Feku': 'The Man of India',\n",
    "        'deplorables': 'deplorable',\n",
    "        'muhajirs': 'Muslim immigrants',\n",
    "        'Brexiters': 'British Exit supporters',\n",
    "        'Brexiteers': 'British Exit supporters',\n",
    "        'Brexiting': 'British Exit',\n",
    "        'Gujratis': 'Gujarati',\n",
    "        'Chutiya': 'Tibet people',\n",
    "        'thighing': 'masturbate',\n",
    "        '卐': 'Nazi Germany',\n",
    "        'rohingyas': 'Muslim ethnic group',\n",
    "        'Pribumi': 'Native Indonesians',\n",
    "        'Gurmehar': 'Gurmehar Kaur Indian student activist',\n",
    "        'Novichok': 'Soviet Union agents',\n",
    "        'Khazari': 'Khazars',\n",
    "        'Demonetization': 'demonetization',\n",
    "        'demonetisation': 'demonetization',\n",
    "        'cryptocurrencies': 'bitcoin',\n",
    "        'Hindians': 'offensive Indian',\n",
    "        'vaxxers': 'vocal nationalists',\n",
    "        'remoaners': 'remainer',\n",
    "        'Jewism': 'Judaism',\n",
    "        'Eroupian': 'European',\n",
    "        'WMAF': 'White male Asian female',\n",
    "        'moeslim': 'Muslim',\n",
    "        'cishet': 'cisgender and heterosexual person',\n",
    "        'Eurocentrics': 'Eurocentrism',\n",
    "        'Jewdar': 'Jew dar',\n",
    "        'Asifas': 'abduction, rape, murder case',\n",
    "        'marathis': 'Marathi',\n",
    "        'Trumpanzees': 'Trump chimpanzee',\n",
    "        'quoras': 'Quora',\n",
    "        'Crimeans': 'Crimea people',\n",
    "        'atrracted': 'attract',\n",
    "        'LGBT': 'lesbian, gay, bisexual, transgender',\n",
    "        'Boshniaks': 'Bosniaks',\n",
    "        'Myeshia': 'widow of Green Beret killed in Niger',\n",
    "        'demcoratic': 'Democratic',\n",
    "        'raaping': 'rape',\n",
    "        'Dönmeh': 'Islam',\n",
    "        'feminazism': 'feminism nazi',\n",
    "        'Quroa': 'Quora',\n",
    "        'QUORA': 'Quora',\n",
    "        'langague': 'language',\n",
    "        '(H|h)ongkongese': 'HongKong people',\n",
    "        '(K|k)ashmirians': 'Kashmirian',\n",
    "        '(C|c)hodu': 'fucker',\n",
    "        'penish': 'penis',\n",
    "        'micropenis': 'small penis',\n",
    "        'Madridiots': 'Madrid idiot',\n",
    "        'Ambedkarites': 'Dalit Buddhist movement',\n",
    "        'ReleaseTheMemo': 'cry for the right and Trump supporters',\n",
    "        'harrase': 'harass',\n",
    "        '(B|b)arracoon': 'Black slave',\n",
    "        '(C|c)astrater': 'castration',\n",
    "        '(R|r)apistan': 'rapist Pakistan',\n",
    "        '(T|t)urkified': 'Turkification',\n",
    "        'Dumbassistan': 'dumb ass Pakistan',\n",
    "        'facetards': 'Facebook retards',\n",
    "        'rapefugees': 'rapist refugee',\n",
    "        'superficious': 'superficial',\n",
    "        # extra from kagglers\n",
    "        'colour': 'color',\n",
    "        'centre': 'center',\n",
    "        'favourite': 'favorite',\n",
    "        'travelling': 'traveling',\n",
    "        'counselling': 'counseling',\n",
    "        'theatre': 'theater',\n",
    "        'cancelled': 'canceled',\n",
    "        'labour': 'labor',\n",
    "        'organisation': 'organization',\n",
    "        'wwii': 'world war 2',\n",
    "        'citicise': 'criticize',\n",
    "        'youtu ': 'youtube ',\n",
    "        'Qoura': 'Quora',\n",
    "        'sallary': 'salary',\n",
    "        'Whta': 'What',\n",
    "        'narcisist': 'narcissist',\n",
    "        'narcissit': 'narcissist',\n",
    "        'howdo': 'how do',\n",
    "        'whatare': 'what are',\n",
    "        'howcan': 'how can',\n",
    "        'howmuch': 'how much',\n",
    "        'howmany': 'how many',\n",
    "        'whydo': 'why do',\n",
    "        'doI': 'do I',\n",
    "        'theBest': 'the best',\n",
    "        'howdoes': 'how does',\n",
    "        'mastrubation': 'masturbation',\n",
    "        'mastrubate': 'masturbate',\n",
    "        'mastrubating': 'masturbating',\n",
    "        'pennis': 'penis',\n",
    "        'Etherium': 'Ethereum',\n",
    "        'bigdata': 'big data',\n",
    "        '2k17': '2017',\n",
    "        '2k18': '2018',\n",
    "        'qouta': 'quota',\n",
    "        'exboyfriend': 'ex boyfriend',\n",
    "        'airhostess': 'air hostess',\n",
    "        'whst': 'what',\n",
    "        'watsapp': 'whatsapp',\n",
    "        'demonitisation': 'demonetization',\n",
    "        'demonitization': 'demonetization',\n",
    "        'demonetisation': 'demonetization'\n",
    "    }\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_to_sub.keys()))\n",
    "\n",
    "    def _replace(match):\n",
    "        \"\"\"\n",
    "        reference: https://www.kaggle.com/hengzheng/attention-capsule-why-not-both-lb-0-694 # noqa\n",
    "        \"\"\"\n",
    "        return misspell_to_sub.get(match.group(0), match.group(0))\n",
    "    return misspell_re.sub(_replace, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf0MXRcHNeTK"
   },
   "outputs": [],
   "source": [
    "def spacing_misspell(text):\n",
    "    \"\"\"\n",
    "    'deadbody' -> 'dead body'\n",
    "    \"\"\"\n",
    "    misspell_list = [\n",
    "        'body',\n",
    "        '(D|d)ead',\n",
    "        '(N|n)orth',\n",
    "        '(K|k)orea',\n",
    "        'matrix',\n",
    "        '(S|s)hit',\n",
    "        '(F|f)uck',\n",
    "        '(F|f)uk',\n",
    "        '(F|f)ck',\n",
    "        '(D|d)ick',\n",
    "        'Trump',\n",
    "        '\\W(A|a)nti',\n",
    "        '(W|w)hy',\n",
    "        # 'Jew',\n",
    "        'bait',\n",
    "        'care',\n",
    "        'troll',\n",
    "        'over',\n",
    "        'gender',\n",
    "        'people',\n",
    "        'kind',\n",
    "        '(S|s)ick',\n",
    "        '(S|s)uck',\n",
    "        '(I|i)diot',\n",
    "        # 'hole(s|)\\W',\n",
    "        '(B|b)ooty',\n",
    "        '(C|c)oin(s|)\\W',\n",
    "        '\\W(N|n)igger'\n",
    "    ]\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_list))\n",
    "    return misspell_re.sub(r\" \\1 \", text)\n",
    "\n",
    "\n",
    "def clean_latex(text):\n",
    "    \"\"\"\n",
    "    convert r\"[math]\\vec{x} + \\vec{y}\" to English\n",
    "    \"\"\"\n",
    "    # edge case\n",
    "    text = re.sub(r'\\[math\\]', ' LaTex math ', text)\n",
    "    text = re.sub(r'\\[\\/math\\]', ' LaTex math ', text)\n",
    "    text = re.sub(r'\\\\', ' LaTex ', text)\n",
    "\n",
    "    pattern_to_sub = {\n",
    "        r'\\\\mathrm': ' LaTex math mode ',\n",
    "        r'\\\\mathbb': ' LaTex math mode ',\n",
    "        r'\\\\boxed': ' LaTex equation ',\n",
    "        r'\\\\begin': ' LaTex equation ',\n",
    "        r'\\\\end': ' LaTex equation ',\n",
    "        r'\\\\left': ' LaTex equation ',\n",
    "        r'\\\\right': ' LaTex equation ',\n",
    "        r'\\\\(over|under)brace': ' LaTex equation ',\n",
    "        r'\\\\text': ' LaTex equation ',\n",
    "        r'\\\\vec': ' vector ',\n",
    "        r'\\\\var': ' variable ',\n",
    "        r'\\\\theta': ' theta ',\n",
    "        r'\\\\mu': ' average ',\n",
    "        r'\\\\min': ' minimum ',\n",
    "        r'\\\\max': ' maximum ',\n",
    "        r'\\\\sum': ' + ',\n",
    "        r'\\\\times': ' * ',\n",
    "        r'\\\\cdot': ' * ',\n",
    "        r'\\\\hat': ' ^ ',\n",
    "        r'\\\\frac': ' / ',\n",
    "        r'\\\\div': ' / ',\n",
    "        r'\\\\sin': ' Sine ',\n",
    "        r'\\\\cos': ' Cosine ',\n",
    "        r'\\\\tan': ' Tangent ',\n",
    "        r'\\\\infty': ' infinity ',\n",
    "        r'\\\\int': ' integer ',\n",
    "        r'\\\\in': ' in ',\n",
    "    }\n",
    "    # post process for look up\n",
    "    pattern_dict = {k.strip('\\\\'): v for k, v in pattern_to_sub.items()}\n",
    "    # init re\n",
    "    patterns = pattern_to_sub.keys()\n",
    "    pattern_re = re.compile('(%s)' % '|'.join(patterns))\n",
    "\n",
    "    def _replace(match):\n",
    "        \"\"\"\n",
    "        reference: https://www.kaggle.com/hengzheng/attention-capsule-why-not-both-lb-0-694 # noqa\n",
    "        \"\"\"\n",
    "        return pattern_dict.get(match.group(0).strip('\\\\'), match.group(0))\n",
    "    return pattern_re.sub(_replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8CJOPVQNjvb"
   },
   "outputs": [],
   "source": [
    "def normalize_unicode(text):\n",
    "    \"\"\"\n",
    "    unicode string normalization\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize('NFKD', text)\n",
    "\n",
    "\n",
    "def remove_newline(text):\n",
    "    \"\"\"\n",
    "    remove \\n and  \\t\n",
    "    \"\"\"\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\t', ' ', text)\n",
    "    text = re.sub('\\b', ' ', text)\n",
    "    text = re.sub('\\r', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def decontracted(text):\n",
    "    \"\"\"\n",
    "    de-contract the contraction\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    text = re.sub(r\"(W|w)on(\\'|\\’)t\", \"will not\", text)\n",
    "    text = re.sub(r\"(C|c)an(\\'|\\’)t\", \"can not\", text)\n",
    "    text = re.sub(r\"(Y|y)(\\'|\\’)all\", \"you all\", text)\n",
    "    text = re.sub(r\"(Y|y)a(\\'|\\’)ll\", \"you all\", text)\n",
    "\n",
    "    # general\n",
    "    text = re.sub(r\"(I|i)(\\'|\\’)m\", \"i am\", text)\n",
    "    text = re.sub(r\"(A|a)in(\\'|\\’)t\", \"is not\", text)\n",
    "    text = re.sub(r\"n(\\'|\\’)t\", \" not\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)re\", \" are\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)s\", \" is\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)d\", \" would\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ll\", \" will\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)t\", \" not\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ve\", \" have\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def spacing_punctuation(text):\n",
    "    \"\"\"\n",
    "    add space before and after punctuation and symbols\n",
    "    \"\"\"\n",
    "    regular_punct = list(string.punctuation)\n",
    "    extra_punct = [\n",
    "        ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "        '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    "        '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
    "        '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
    "        '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
    "        '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
    "        '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "        'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
    "        '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
    "        '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
    "    all_punct = ''.join(sorted(list(set(regular_punct + extra_punct))))\n",
    "    re_tok = re.compile(f'([{all_punct}])')\n",
    "    return re_tok.sub(r' \\1 ', text)\n",
    "\n",
    "\n",
    "def spacing_digit(text):\n",
    "    \"\"\"\n",
    "    add space before and after digits\n",
    "    \"\"\"\n",
    "    re_tok = re.compile('([0-9])')\n",
    "    return re_tok.sub(r' \\1 ', text)\n",
    "\n",
    "\n",
    "def spacing_number(text):\n",
    "    \"\"\"\n",
    "    add space before and after numbers\n",
    "    \"\"\"\n",
    "    re_tok = re.compile('([0-9]{1,})')\n",
    "    return re_tok.sub(r' \\1 ', text)\n",
    "\n",
    "\n",
    "def remove_number(text):\n",
    "    \"\"\"\n",
    "    numbers are not toxic\n",
    "    \"\"\"\n",
    "    return re.sub('\\d+', ' ', text)\n",
    "\n",
    "\n",
    "def remove_space(text):\n",
    "    \"\"\"\n",
    "    remove extra spaces and ending space if any\n",
    "    \"\"\"\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub('\\s+$', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rg9eCPnxN2Gk"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, remove_num=True):\n",
    "    \"\"\"\n",
    "    preprocess text into clean text for tokenization\n",
    "    NOTE:\n",
    "        1. glove supports uppper case words\n",
    "        2. glove supports digit\n",
    "        3. glove supports punctuation\n",
    "        5. glove supports domains e.g. www.apple.com\n",
    "        6. glove supports misspelled words e.g. FUCKKK\n",
    "    \"\"\"\n",
    "    # # 1. normalize\n",
    "    # text = normalize_unicode(text)\n",
    "    # # 2. remove new line\n",
    "    # text = remove_newline(text)\n",
    "    # 3. de-contract\n",
    "    text = decontracted(text)\n",
    "    # 4. clean misspell\n",
    "    text = clean_misspell(text)\n",
    "    # 5. space misspell\n",
    "    text = spacing_misspell(text)\n",
    "    # 6. clean_latex\n",
    "    text = clean_latex(text)\n",
    "    # 7. space\n",
    "    text = spacing_punctuation(text)\n",
    "    # 8. handle number\n",
    "    if remove_num:\n",
    "        text = remove_number(text)\n",
    "    else:\n",
    "        text = spacing_digit(text)\n",
    "    # 9. remove space\n",
    "    text = remove_space(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCmVch_OHo-O"
   },
   "outputs": [],
   "source": [
    "df_main['question_text'] = df_main['question_text'].apply(lambda s : preprocess(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyscrap8nHVo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "LWDlFMfTnHVq",
    "outputId": "df2a3e12-a555-44cb-b477-5adaa4611327"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tLiHCl-nHVs"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "\n",
    "question_words = list()\n",
    "lines = df_main['question_text'].values.tolist()\n",
    "\n",
    "for line in lines:   \n",
    "    tokens = word_tokenize(line)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word    \n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    question_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "X2SGww2_nHVu",
    "outputId": "c19bee82-1768-4a8e-a48c-bcaa2400f001"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "EMBEDDING_DIM = 100\n",
    "# train word2vec model\n",
    "model = gensim.models.Word2Vec(sentences=question_words, size=EMBEDDING_DIM, window=1, workers=4, min_count=1)\n",
    "# vocab size\n",
    "words = list(model.wv.vocab)\n",
    "print('Vocabulary size: %d' % len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "ACURiqGNnHVw",
    "outputId": "03d77212-89ac-4c0e-e5ff-55d5f9319163"
   },
   "outputs": [],
   "source": [
    "filename = 'embedding_word2vec.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "VlXB9NQwnHVy",
    "outputId": "1904e375-577d-4233-ea80-90487bb052a1"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00NhmaD1nHV0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('', 'embedding_word2vec.txt'),  encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFuSINQOoUFt"
   },
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(df_main['question_text'],df_main.target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9cqx1vhnHV2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9HNkxcnsnHV5",
    "outputId": "5dfbe0b2-f3a5-4e6d-c89a-951d12574ff9"
   },
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(question_words)\n",
    "sequences = tokenizer_obj.texts_to_sequences(question_words)\n",
    "# pad sequences\n",
    "word_index = tokenizer_obj.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "pSI5op6vnHV7",
    "outputId": "221f0e3a-6c56-4da3-803a-b5148b8d1534"
   },
   "outputs": [],
   "source": [
    "review_pad = pad_sequences(sequences, maxlen=100)\n",
    "sentiment =  df_main['target'].values\n",
    "print('Shape of review tensor:', review_pad.shape)\n",
    "print('Shape of sentiment tensor:', sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8z-FVRhnHV-"
   },
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = sentiment[indices]\n",
    "num_validation_samples = int(0.2 * review_pad.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZ1XM9H4nHWA"
   },
   "outputs": [],
   "source": [
    "X_train_pad = review_pad[:-num_validation_samples]\n",
    "y_train = sentiment[:-num_validation_samples]\n",
    "X_test_pad = review_pad[-num_validation_samples:]\n",
    "y_test = sentiment[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "mkL15uo8nHWC",
    "outputId": "65733f7c-84b1-488e-f657-2b247f89a769"
   },
   "outputs": [],
   "source": [
    "print('Shape of X_train_pad tensor:', X_train_pad)\n",
    "print('Shape of y_train tensor:', y_train)\n",
    "\n",
    "print('Shape of X_test_pad tensor:', X_test_pad)\n",
    "print('Shape of y_test tensor:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYlLpMEgnHWD"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM =100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5RcnjuVnHWU"
   },
   "outputs": [],
   "source": [
    "from keras.initializers import Constant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "NOlJ1ZY8nHWY",
    "outputId": "e5ed450d-8d24-4000-f5b4-531aaab871bc"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=100,\n",
    "                            trainable=False))\n",
    "model.add(Bidirectional(LSTM(300,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(300,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(300,return_sequences=True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "JqNkINR4nHWb",
    "outputId": "35342af7-80dc-432e-feb5-094c8e40ad01"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_pad, y_train, batch_size=1024, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "lQsAkq5qwdlX",
    "outputId": "0ff87323-455d-45f8-b34b-3e7ffcbab586"
   },
   "outputs": [],
   "source": [
    "print(X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igabnOAbnHWe"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test_pad,batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "eb8P_Ah3nHWg",
    "outputId": "9f7132ac-fa84-4f32-d253-b9ba7b98a72c"
   },
   "outputs": [],
   "source": [
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WVJBZzcnHWi"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "PLACT1n3nHWk",
    "outputId": "46dee513-f7b7-48ff-8753-b4b6e799ad99"
   },
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDzFh5GKwyF1"
   },
   "outputs": [],
   "source": [
    "def line_search_f1_score(y_score, y_test):\n",
    "    max_f1_score = 0\n",
    "    opt_threshold = 0\n",
    "    for threshold in [i*0.01 for i in range(100)]:\n",
    "        y_preds = y_score > threshold\n",
    "        score = f1_score(y_preds, y_test)\n",
    "        if max_f1_score < score:\n",
    "            max_f1_score = score\n",
    "            opt_threshold = threshold\n",
    "    return max_f1_score, opt_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lWt8nQKw7OL"
   },
   "outputs": [],
   "source": [
    "max_f1_score, threshold = line_search_f1_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "D64VGdRkxA-F",
    "outputId": "c0e51f47-86d6-4add-c388-d036a24382fc"
   },
   "outputs": [],
   "source": [
    "print(max_f1_score, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YiNjwPSxEC9"
   },
   "outputs": [],
   "source": [
    "predictions = [1 if x>=0.33 else 0 for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xOb_XxxxJGc"
   },
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "S6q3YsiyxMMj",
    "outputId": "9090bae5-cf3f-4387-e4c2-4942de7f9526"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "TGK4vFogxW39",
    "outputId": "769576c7-cf70-4075-cd00-4c222315a805"
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VI3kLtly5zWa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_Word2Vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
