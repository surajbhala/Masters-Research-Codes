{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ceiYxv9fgxx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py --sys-prefix widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension interpret-text-widget/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable interpret_text.experimental.widget --py --sys-prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set QUICK_RUN = True to run the notebook on a small subset of data and a smaller number of epochs.\n",
    "QUICK_RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkZEBPnnfbiQ"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scrapbook as sb\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import unicodedata\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from interpret_text.experimental.common.utils_bert import Language, Tokenizer, BERTSequenceClassifier\n",
    "from interpret_text.experimental.common.timer import Timer\n",
    "from interpret_text.experimental.widget import ExplanationDashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4j71hHEtfbDD"
   },
   "outputs": [],
   "source": [
    "from interpret_text.experimental.unified_information import UnifiedInformationExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R00MPA9SePBh"
   },
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_DATA_FRACTION = 1\n",
    "TEST_DATA_FRACTION = 1\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    BATCH_SIZE = 1\n",
    "else:\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "DATA_FOLDER = \"./temp\"\n",
    "BERT_CACHE_DIR = \"./temp\"\n",
    "LANGUAGE = Language.ENGLISH\n",
    "TO_LOWER = True\n",
    "MAX_LEN = 150\n",
    "BATCH_SIZE_PRED = 512\n",
    "TRAIN_SIZE = 0.8\n",
    "LABEL_COL = \"genre\"\n",
    "TEXT_COL = \"sentence1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rq6XsrkCsBEb"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def clean_misspell(text):\n",
    "    \"\"\"\n",
    "    misspell list (quora vs. glove)\n",
    "    \"\"\"\n",
    "    misspell_to_sub = {\n",
    "        '(T|t)erroristan': 'terrorist Pakistan',\n",
    "        'BIMARU': 'Bihar, Madhya Pradesh, Rajasthan, Uttar Pradesh',\n",
    "        '(H|h)induphobic': 'Hindu phobic',\n",
    "        '(H|h)induphobia': 'Hindu phobic',\n",
    "        'Babchenko': 'Arkady Arkadyevich Babchenko faked death',\n",
    "        'Boshniaks': 'Bosniaks',\n",
    "        'Dravidanadu': 'Dravida Nadu',\n",
    "        'mysoginists': 'misogynists',\n",
    "        'MGTOWS': 'Men Going Their Own Way',\n",
    "        'mongloid': 'Mongoloid',\n",
    "        'unsincere': 'insincere',\n",
    "        'meninism': 'male feminism',\n",
    "        'jewplicate': 'jewish replicate',\n",
    "        'unoin': 'Union',\n",
    "        'daesh': 'Islamic State of Iraq and the Levant',\n",
    "        'Kalergi': 'Coudenhove-Kalergi',\n",
    "        ' apist': ' Ape',\n",
    "        '(B|b)hakts': 'Bhakt',\n",
    "        'Tambrahms': 'Tamil Brahmin',\n",
    "        'Pahul': 'Amrit Sanskar',\n",
    "        'SJW(s|)': 'social justice warrior',\n",
    "        'incel(s|)': 'involuntary celibates',\n",
    "        'emiratis': 'Emiratis',\n",
    "        'weatern': 'western',\n",
    "        'Pizzagate': 'Pizzagate conspiracy theory',\n",
    "        'naïve': 'naive',\n",
    "        'Skripal': 'Sergei Skripal',\n",
    "        '(R|r)emainers': 'remainer',\n",
    "        'antibrahmin': 'anti Brahminism',\n",
    "        'HYPSM': ' Harvard, Yale, Princeton, Stanford, MIT',\n",
    "        'HYPS': ' Harvard, Yale, Princeton, Stanford',\n",
    "        'kompromat': 'compromising material',\n",
    "        '(T|t)harki': 'pervert',\n",
    "        'mastuburate': 'masturbate',\n",
    "        'Zoë': 'Zoe',\n",
    "        'indans': 'Indian',\n",
    "        'xender': 'gender',\n",
    "        'Naxali': 'Naxalite',\n",
    "        'Bathla': 'Namit Bathla',\n",
    "        'Mewani': 'Indian politician Jignesh Mevani',\n",
    "        'clichéd': 'cliché',\n",
    "        'cliché(s|)': 'cliché',\n",
    "        'Wjy': 'Why',\n",
    "        'Fadnavis': 'Indian politician Devendra Fadnavis',\n",
    "        'Awadesh': 'Indian engineer Awdhesh Singh',\n",
    "        'Awdhesh': 'Indian engineer Awdhesh Singh',\n",
    "        'Khalistanis': 'Sikh separatist movement',\n",
    "        'madheshi': 'Madheshi',\n",
    "        'Quorans': 'Quoran',\n",
    "        'BNBR': 'Be Nice, Be Respectful',\n",
    "        'Bolsonaro': 'Jair Bolsonaro',\n",
    "        'XXXTentacion': 'Tentacion',\n",
    "        'Padmavat': 'Indian Movie Padmaavat',\n",
    "        'Žižek': 'Slovenian philosopher Slavoj Žižek',\n",
    "        'Adityanath': 'Indian monk Yogi Adityanath',\n",
    "        '(B|b)rexit': 'British Exit',\n",
    "        'jallikattu': 'Jallikattu',\n",
    "        'fortnite': 'Fortnite',\n",
    "        'Swachh': 'Swachh Bharat mission campaign',\n",
    "        'Qoura': 'Quora',\n",
    "        'narcissit': 'narcissist',\n",
    "        # extra in sample\n",
    "        'Doklam': 'Tibet',\n",
    "        'Drumpf': 'Donald Trump',\n",
    "        'Strzok': 'Hillary Clinton scandal',\n",
    "        'rohingya': 'Rohingya',\n",
    "        'wumao': 'offensive Chinese',\n",
    "        'Sanghis': 'Sanghi',\n",
    "        'Tamilans': 'Tamils',\n",
    "        'biharis': 'Biharis',\n",
    "        'Rejuvalex': 'hair growth formula',\n",
    "        'Feku': 'The Man of India',\n",
    "        'deplorables': 'deplorable',\n",
    "        'muhajirs': 'Muslim immigrants',\n",
    "        'Brexiters': 'British Exit supporters',\n",
    "        'Brexiteers': 'British Exit supporters',\n",
    "        'Brexiting': 'British Exit',\n",
    "        'Gujratis': 'Gujarati',\n",
    "        'Chutiya': 'Tibet people',\n",
    "        'thighing': 'masturbate',\n",
    "        '卐': 'Nazi Germany',\n",
    "        'rohingyas': 'Muslim ethnic group',\n",
    "        'Pribumi': 'Native Indonesians',\n",
    "        'Gurmehar': 'Gurmehar Kaur Indian student activist',\n",
    "        'Novichok': 'Soviet Union agents',\n",
    "        'Khazari': 'Khazars',\n",
    "        'Demonetization': 'demonetization',\n",
    "        'demonetisation': 'demonetization',\n",
    "        'cryptocurrencies': 'bitcoin',\n",
    "        'Hindians': 'offensive Indian',\n",
    "        'vaxxers': 'vocal nationalists',\n",
    "        'remoaners': 'remainer',\n",
    "        'Jewism': 'Judaism',\n",
    "        'Eroupian': 'European',\n",
    "        'WMAF': 'White male Asian female',\n",
    "        'moeslim': 'Muslim',\n",
    "        'cishet': 'cisgender and heterosexual person',\n",
    "        'Eurocentrics': 'Eurocentrism',\n",
    "        'Jewdar': 'Jew dar',\n",
    "        'Asifas': 'abduction, rape, murder case',\n",
    "        'marathis': 'Marathi',\n",
    "        'Trumpanzees': 'Trump chimpanzee',\n",
    "        'quoras': 'Quora',\n",
    "        'Crimeans': 'Crimea people',\n",
    "        'atrracted': 'attract',\n",
    "        'LGBT': 'lesbian, gay, bisexual, transgender',\n",
    "        'Boshniaks': 'Bosniaks',\n",
    "        'Myeshia': 'widow of Green Beret killed in Niger',\n",
    "        'demcoratic': 'Democratic',\n",
    "        'raaping': 'rape',\n",
    "        'Dönmeh': 'Islam',\n",
    "        'feminazism': 'feminism nazi',\n",
    "        'Quroa': 'Quora',\n",
    "        'QUORA': 'Quora',\n",
    "        'langague': 'language',\n",
    "        '(H|h)ongkongese': 'HongKong people',\n",
    "        '(K|k)ashmirians': 'Kashmirian',\n",
    "        '(C|c)hodu': 'fucker',\n",
    "        'penish': 'penis',\n",
    "        'micropenis': 'small penis',\n",
    "        'Madridiots': 'Madrid idiot',\n",
    "        'Ambedkarites': 'Dalit Buddhist movement',\n",
    "        'ReleaseTheMemo': 'cry for the right and Trump supporters',\n",
    "        'harrase': 'harass',\n",
    "        '(B|b)arracoon': 'Black slave',\n",
    "        '(C|c)astrater': 'castration',\n",
    "        '(R|r)apistan': 'rapist Pakistan',\n",
    "        '(T|t)urkified': 'Turkification',\n",
    "        'Dumbassistan': 'dumb ass Pakistan',\n",
    "        'facetards': 'Facebook retards',\n",
    "        'rapefugees': 'rapist refugee',\n",
    "        'superficious': 'superficial',\n",
    "        # extra from kagglers\n",
    "        'colour': 'color',\n",
    "        'centre': 'center',\n",
    "        'favourite': 'favorite',\n",
    "        'travelling': 'traveling',\n",
    "        'counselling': 'counseling',\n",
    "        'theatre': 'theater',\n",
    "        'cancelled': 'canceled',\n",
    "        'labour': 'labor',\n",
    "        'organisation': 'organization',\n",
    "        'wwii': 'world war 2',\n",
    "        'citicise': 'criticize',\n",
    "        'youtu ': 'youtube ',\n",
    "        'Qoura': 'Quora',\n",
    "        'sallary': 'salary',\n",
    "        'Whta': 'What',\n",
    "        'narcisist': 'narcissist',\n",
    "        'narcissit': 'narcissist',\n",
    "        'howdo': 'how do',\n",
    "        'whatare': 'what are',\n",
    "        'howcan': 'how can',\n",
    "        'howmuch': 'how much',\n",
    "        'howmany': 'how many',\n",
    "        'whydo': 'why do',\n",
    "        'doI': 'do I',\n",
    "        'theBest': 'the best',\n",
    "        'howdoes': 'how does',\n",
    "        'mastrubation': 'masturbation',\n",
    "        'mastrubate': 'masturbate',\n",
    "        'mastrubating': 'masturbating',\n",
    "        'pennis': 'penis',\n",
    "        'Etherium': 'Ethereum',\n",
    "        'bigdata': 'big data',\n",
    "        '2k17': '2017',\n",
    "        '2k18': '2018',\n",
    "        'qouta': 'quota',\n",
    "        'exboyfriend': 'ex boyfriend',\n",
    "        'airhostess': 'air hostess',\n",
    "        'whst': 'what',\n",
    "        'watsapp': 'whatsapp',\n",
    "        'demonitisation': 'demonetization',\n",
    "        'demonitization': 'demonetization',\n",
    "        'demonetisation': 'demonetization'\n",
    "    }\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_to_sub.keys()))\n",
    "\n",
    "    def _replace(match):\n",
    "        \"\"\"\n",
    "        reference: https://www.kaggle.com/hengzheng/attention-capsule-why-not-both-lb-0-694 # noqa\n",
    "        \"\"\"\n",
    "        return misspell_to_sub.get(match.group(0), match.group(0))\n",
    "    return misspell_re.sub(_replace, text)\n",
    "def spacing_misspell(text):\n",
    "    \"\"\"\n",
    "    'deadbody' -> 'dead body'\n",
    "    \"\"\"\n",
    "    misspell_list = [\n",
    "        'body',\n",
    "        '(D|d)ead',\n",
    "        '(N|n)orth',\n",
    "        '(K|k)orea',\n",
    "        'matrix',\n",
    "        '(S|s)hit',\n",
    "        '(F|f)uck',\n",
    "        '(F|f)uk',\n",
    "        '(F|f)ck',\n",
    "        '(D|d)ick',\n",
    "        'Trump',\n",
    "        '\\W(A|a)nti',\n",
    "        '(W|w)hy',\n",
    "        # 'Jew',\n",
    "        'bait',\n",
    "        'care',\n",
    "        'troll',\n",
    "        'over',\n",
    "        'gender',\n",
    "        'people',\n",
    "        'kind',\n",
    "        '(S|s)ick',\n",
    "        '(S|s)uck',\n",
    "        '(I|i)diot',\n",
    "        # 'hole(s|)\\W',\n",
    "        '(B|b)ooty',\n",
    "        '(C|c)oin(s|)\\W',\n",
    "        '\\W(N|n)igger'\n",
    "    ]\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_list))\n",
    "    return misspell_re.sub(r\" \\1 \", text)\n",
    "\n",
    "\n",
    "def clean_latex(text):\n",
    "    \"\"\"\n",
    "    convert r\"[math]\\vec{x} + \\vec{y}\" to English\n",
    "    \"\"\"\n",
    "    # edge case\n",
    "    text = re.sub(r'\\[math\\]', ' LaTex math ', text)\n",
    "    text = re.sub(r'\\[\\/math\\]', ' LaTex math ', text)\n",
    "    text = re.sub(r'\\\\', ' LaTex ', text)\n",
    "\n",
    "    pattern_to_sub = {\n",
    "        r'\\\\mathrm': ' LaTex math mode ',\n",
    "        r'\\\\mathbb': ' LaTex math mode ',\n",
    "        r'\\\\boxed': ' LaTex equation ',\n",
    "        r'\\\\begin': ' LaTex equation ',\n",
    "        r'\\\\end': ' LaTex equation ',\n",
    "        r'\\\\left': ' LaTex equation ',\n",
    "        r'\\\\right': ' LaTex equation ',\n",
    "        r'\\\\(over|under)brace': ' LaTex equation ',\n",
    "        r'\\\\text': ' LaTex equation ',\n",
    "        r'\\\\vec': ' vector ',\n",
    "        r'\\\\var': ' variable ',\n",
    "        r'\\\\theta': ' theta ',\n",
    "        r'\\\\mu': ' average ',\n",
    "        r'\\\\min': ' minimum ',\n",
    "        r'\\\\max': ' maximum ',\n",
    "        r'\\\\sum': ' + ',\n",
    "        r'\\\\times': ' * ',\n",
    "        r'\\\\cdot': ' * ',\n",
    "        r'\\\\hat': ' ^ ',\n",
    "        r'\\\\frac': ' / ',\n",
    "        r'\\\\div': ' / ',\n",
    "        r'\\\\sin': ' Sine ',\n",
    "        r'\\\\cos': ' Cosine ',\n",
    "        r'\\\\tan': ' Tangent ',\n",
    "        r'\\\\infty': ' infinity ',\n",
    "        r'\\\\int': ' integer ',\n",
    "        r'\\\\in': ' in ',\n",
    "    }\n",
    "    # post process for look up\n",
    "    pattern_dict = {k.strip('\\\\'): v for k, v in pattern_to_sub.items()}\n",
    "    # init re\n",
    "    patterns = pattern_to_sub.keys()\n",
    "    pattern_re = re.compile('(%s)' % '|'.join(patterns))\n",
    "\n",
    "    def _replace(match):\n",
    "        \"\"\"\n",
    "        reference: https://www.kaggle.com/hengzheng/attention-capsule-why-not-both-lb-0-694 # noqa\n",
    "        \"\"\"\n",
    "        return pattern_dict.get(match.group(0).strip('\\\\'), match.group(0))\n",
    "    return pattern_re.sub(_replace, text)\n",
    "def normalize_unicode(text):\n",
    "    \"\"\"\n",
    "    unicode string normalization\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize('NFKD', text)\n",
    "\n",
    "\n",
    "def remove_newline(text):\n",
    "    \"\"\"\n",
    "    remove \\n and  \\t\n",
    "    \"\"\"\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\t', ' ', text)\n",
    "    text = re.sub('\\b', ' ', text)\n",
    "    text = re.sub('\\r', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def decontracted(text):\n",
    "    \"\"\"\n",
    "    de-contract the contraction\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    text = re.sub(r\"(W|w)on(\\'|\\’)t\", \"will not\", text)\n",
    "    text = re.sub(r\"(C|c)an(\\'|\\’)t\", \"can not\", text)\n",
    "    text = re.sub(r\"(Y|y)(\\'|\\’)all\", \"you all\", text)\n",
    "    text = re.sub(r\"(Y|y)a(\\'|\\’)ll\", \"you all\", text)\n",
    "\n",
    "    # general\n",
    "    text = re.sub(r\"(I|i)(\\'|\\’)m\", \"i am\", text)\n",
    "    text = re.sub(r\"(A|a)in(\\'|\\’)t\", \"is not\", text)\n",
    "    text = re.sub(r\"n(\\'|\\’)t\", \" not\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)re\", \" are\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)s\", \" is\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)d\", \" would\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ll\", \" will\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)t\", \" not\", text)\n",
    "    text = re.sub(r\"(\\'|\\’)ve\", \" have\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def spacing_punctuation(text):\n",
    "    \"\"\"\n",
    "    add space before and after punctuation and symbols\n",
    "    \"\"\"\n",
    "    regular_punct = list(string.punctuation)\n",
    "    extra_punct = [\n",
    "        ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "        '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    "        '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
    "        '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
    "        '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
    "        '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
    "        '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "        'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
    "        '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
    "        '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
    "    all_punct = ''.join(sorted(list(set(regular_punct + extra_punct))))\n",
    "    re_tok = re.compile(f'([{all_punct}])')\n",
    "    return re_tok.sub(r' \\1 ', text)\n",
    "\n",
    "\n",
    "def spacing_digit(text):\n",
    "    \"\"\"\n",
    "    add space before and after digits\n",
    "    \"\"\"\n",
    "    re_tok = re.compile('([0-9])')\n",
    "    return re_tok.sub(r' \\1 ', text)\n",
    "\n",
    "\n",
    "def spacing_number(text):\n",
    "    \"\"\"\n",
    "    add space before and after numbers\n",
    "    \"\"\"\n",
    "    re_tok = re.compile('([0-9]{1,})')\n",
    "    return re_tok.sub(r' \\1 ', text)\n",
    "\n",
    "\n",
    "def remove_number(text):\n",
    "    \"\"\"\n",
    "    numbers are not toxic\n",
    "    \"\"\"\n",
    "    return re.sub('\\d+', ' ', text)\n",
    "\n",
    "\n",
    "def remove_space(text):\n",
    "    \"\"\"\n",
    "    remove extra spaces and ending space if any\n",
    "    \"\"\"\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub('\\s+$', '', text)\n",
    "    return text\n",
    "   \n",
    "\n",
    "def preprocess(text, remove_num=True):\n",
    "    \"\"\"\n",
    "    preprocess text into clean text for tokenization\n",
    "    NOTE:\n",
    "        1. glove supports uppper case words\n",
    "        2. glove supports digit\n",
    "        3. glove supports punctuation\n",
    "        5. glove supports domains e.g. www.apple.com\n",
    "        6. glove supports misspelled words e.g. FUCKKK\n",
    "    \"\"\"\n",
    "    # # 1. normalize\n",
    "    text = normalize_unicode(text)\n",
    "    # # 2. remove new line\n",
    "    text = remove_newline(text)\n",
    "    # 3. de-contract\n",
    "    text = decontracted(text)\n",
    "    # 4. clean misspell\n",
    "    text = clean_misspell(text)\n",
    "    # 5. space misspell\n",
    "    text = spacing_misspell(text)\n",
    "    # 6. clean_latex\n",
    "    text = clean_latex(text)\n",
    "    # 7. space\n",
    "    text = spacing_punctuation(text)\n",
    "    # 8. handle number\n",
    "    if remove_num:\n",
    "        text = remove_number(text)\n",
    "    else:\n",
    "        text = spacing_digit(text)\n",
    "    # 9. remove space\n",
    "    text = remove_space(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFJPrl5gePEU"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWoduKghePHM"
   },
   "outputs": [],
   "source": [
    "df_sincere = df.loc[df['target'] == 0]\n",
    "df_insincere = df.loc[df['target'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSM1bWfkePJ_"
   },
   "outputs": [],
   "source": [
    "df_sincere_sampled = df_sincere.sample(500,random_state=42)\n",
    "df_insincere_sampled = df_insincere.sample(500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pp4DPK6zePM3"
   },
   "outputs": [],
   "source": [
    "df_main = pd.concat([df_insincere_sampled,df_sincere_sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_G_vKniDkCwP",
    "outputId": "36faad73-a7ac-465d-82ad-5cfd1529c293"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.drop(['qid'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['question_text'] = df_main['question_text'].apply(lambda s: preprocess(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWFrCV01ePP_"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_main, train_size = 0.8, random_state=24)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "C3o7_r_uePV6",
    "outputId": "cb39b3a7-0b14-48a5-fa40-bfe7a1e22004"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 800/800 [00:00<00:00, 4641.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 3613.27it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = Tokenizer(LANGUAGE, to_lower=TO_LOWER, cache_dir=BERT_CACHE_DIR)\n",
    "\n",
    "tokens_train = tokenizer.tokenize(list(df_train['question_text']))\n",
    "tokens_test = tokenizer.tokenize(list(df_test['question_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLPT_NJgePY_"
   },
   "outputs": [],
   "source": [
    "tokens_train, mask_train, _ = tokenizer.preprocess_classification_tokens(tokens_train, MAX_LEN)\n",
    "tokens_test, mask_test, _ = tokenizer.preprocess_classification_tokens(tokens_test, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IY9WmJ1AePb-",
    "outputId": "e68e2869-1e04-42c5-b83e-e63cd030cb6b"
   },
   "outputs": [],
   "source": [
    "classifier = BERTSequenceClassifier(language=LANGUAGE, num_labels=2, cache_dir=BERT_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "lZTiJ8BSq4J-",
    "outputId": "9d71b2df-efb6-427e-fb66-0a8097e4ebd8"
   },
   "outputs": [],
   "source": [
    "label = df_main['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "tt-esAqakc2S",
    "outputId": "9acf1db3-7f3f-4b7f-a6ea-823640b085ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n",
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████| 100/100 [16:31<00:00,  9.91s/it]\n",
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████| 100/100 [17:40<00:00, 10.60s/it]\n",
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████| 100/100 [16:32<00:00,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training time: 0.846 hrs]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with Timer() as t:\n",
    "    classifier.fit(token_ids=tokens_train,\n",
    "                    input_mask=mask_train,\n",
    "                    labels=df_train['target'],    \n",
    "                    num_epochs=3,\n",
    "                    batch_size=BATCH_SIZE,    \n",
    "                    verbose=True)    \n",
    "print(\"[Training time: {:.3f} hrs]\".format(t.interval / 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cye0q4YLkc8s",
    "outputId": "f78f7eb0-3cb9-4236-b9b1-689c61b45b0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|███████████████████████████████████████████████████████████████████████| 25/25 [01:10<00:00,  2.81s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = classifier.predict(token_ids=tokens_test, \n",
    "                           input_mask=mask_test,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "vGiK03ENqasN",
    "outputId": "165fdc92-b401-45d3-d8c2-e3e1915d0768"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "rROJrGv9kc_D",
    "outputId": "d4b52e38-4cf5-4f08-e9ba-fc25cbd1b8ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.795\n",
      "{\n",
      "    \"0\": {\n",
      "        \"f1-score\": 0.812785388127854,\n",
      "        \"precision\": 0.8165137614678899,\n",
      "        \"recall\": 0.8090909090909091,\n",
      "        \"support\": 110\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"f1-score\": 0.7734806629834255,\n",
      "        \"precision\": 0.7692307692307693,\n",
      "        \"recall\": 0.7777777777777778,\n",
      "        \"support\": 90\n",
      "    },\n",
      "    \"accuracy\": 0.795,\n",
      "    \"macro avg\": {\n",
      "        \"f1-score\": 0.7931330255556397,\n",
      "        \"precision\": 0.7928722653493296,\n",
      "        \"recall\": 0.7934343434343434,\n",
      "        \"support\": 200\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"f1-score\": 0.7950982618128611,\n",
      "        \"precision\": 0.7952364149611856,\n",
      "        \"recall\": 0.795,\n",
      "        \"support\": 200\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df_test['target'], preds,  output_dict=True) \n",
    "accuracy = accuracy_score(df_test['target'], preds)\n",
    "print(\"accuracy: {}\".format(accuracy))\n",
    "print(json.dumps(report, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "v_lN5zrrmtCm",
    "outputId": "368e3cd8-5408-438a-ba04-8c3ca3227aff"
   },
   "outputs": [],
   "source": [
    "#sb.glue(\"accuracy\", accuracy)\n",
    "#sb.glue(\"precision\", report[\"macro avg\"][\"precision\"])\n",
    "#sb.glue(\"recall\", report[\"macro avg\"][\"recall\"])\n",
    "#sb.glue(\"f1\", report[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sWRkpiOKmtFw",
    "outputId": "140c9339-ff55-4ed3-98d6-70fb7fde86e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n",
    "\n",
    "classifier.model.to(device)\n",
    "for param in classifier.model.parameters():\n",
    "    param.requires_grad = False\n",
    "classifier.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CzCvuNggmtIw"
   },
   "outputs": [],
   "source": [
    "\n",
    "interpreter_unified = UnifiedInformationExplainer(model=classifier.model, \n",
    "                                 train_dataset=list(df_train['question_text']), \n",
    "                                 device=device, \n",
    "                                 target_layer=14, \n",
    "                                 classes=df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ezwkHdwPmtL1",
    "outputId": "bf58654f-f9a6-4a02-a89d-f773efa48b5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the best way to move on from a girl ? 0 0\n"
     ]
    }
   ],
   "source": [
    "# 55,56\n",
    "idx = 33\n",
    "text = df_test['question_text'][idx]\n",
    "true_label = df_test['target'][idx]\n",
    "predicted_label = preds[idx]\n",
    "print(text, true_label, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "e3HXh_F-kdB4",
    "outputId": "12d6dadb-090e-4d07-d206-2c23ed2971bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 150/150 [04:22<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "explanation_unified = interpreter_unified.explain_local(text, true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xvhG_1m5oloZ"
   },
   "source": [
    "## Visualize Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "47hcLl7woqWm",
    "outputId": "2e5bf0a5-88ba-4bd8-be03-bbf60629716b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5596439c5a4208a4fbf5d374fdaafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExplanationWidget(value={'text': ['what', 'is', 'the', 'best', 'way', 'to', 'move', 'on', 'from', 'a', 'girl',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<interpret_text.experimental.widget.ExplanationDashboard.ExplanationDashboard at 0x2358c42dac8>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExplanationDashboard(explanation_unified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDfLN1btpT9m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Explainable BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "204106bf44bd4e038601f1e4e1b7c9ac": {
     "model_module": "interpret-text-widget",
     "model_name": "ExplanationModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "interpret-text-widget",
      "_model_module_version": "^0.1.0",
      "_model_name": "ExplanationModel",
      "_view_count": null,
      "_view_module": "interpret-text-widget",
      "_view_module_version": "^0.1.1",
      "_view_name": "ExplanationView",
      "layout": "IPY_MODEL_851f161bdeb34bb2955428b29d70c690",
      "value": {
       "classNames": [
        "fiction",
        "government",
        "slate",
        "telephone",
        "travel"
       ],
       "localExplanations": [
        0.15370258688926697,
        0.3055018186569214,
        0.21882809698581696,
        0.2524109482765198,
        0.16129060089588165,
        0.376742422580719,
        0.2976893484592438,
        0.1875191479921341,
        0.3513529896736145,
        0.17989200353622437,
        0.31747183203697205,
        0.18596947193145752,
        0.22819559276103973,
        0.03129998967051506,
        0.2353915423154831,
        0.38098645210266113,
        0.28918278217315674,
        0.2584957480430603,
        0.20520198345184326,
        0.22841180860996246,
        0.26125648617744446,
        0.11736025661230087,
        0.44923681020736694,
        0.19221949577331543,
        0.4212491810321808,
        0.11248461902141571,
        0.33523622155189514,
        0.35610687732696533,
        0.3488010764122009,
        0.33199766278266907,
        0.44453102350234985,
        0.230620339512825,
        0.20610687136650085,
        0.2619960308074951
       ],
       "prediction": [
        1,
        0,
        1,
        1,
        1
       ],
       "text": [
        "similarly",
        ",",
        "one",
        "organization",
        "'",
        "s",
        "central",
        "group",
        "was",
        "instrumental",
        "in",
        "acquiring",
        "a",
        "strong",
        "user",
        "authentication",
        "system",
        "to",
        "help",
        "ensure",
        "that",
        "network",
        "use",
        "could",
        "be",
        "re",
        "##lia",
        "##bly",
        "traced",
        "to",
        "the",
        "individual",
        "users",
        "."
       ]
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
